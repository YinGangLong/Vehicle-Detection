## 形成最终文档

### 项目各个阶段中的坑

- InceptionV4 Finetune 阶段由于数据下载过程有中断丢失或者 TinyMind 上传存储出现问题等原因，导致训练过程中断，卡了很长时间。各种网上解决方案尝试无果后，下决心重新下载数据，重新建立数据集上传，重新建立项目训练终于解决。
- 分类部分模型对整张图片做 inference 时得到的 score 最高，对按 bounding box 裁切出来的小图得到的 score 次高，两者预处理都采用了 preprocess_for_eval() 即验证集上的预处理函数，包含中心裁切。而如果预处理中没有采用中心裁切的话，score 会继续下降。
- 官方给出的 object detection Notebook 中 vis_util.visualize_boxes_and_labels_on_image_array 函数，在原图上“写”分类结果时对中文支持不好。通过 opencv-python 中一系列 draw 函数来完成。


### 心得体会

- 项目整个 coding 之前建立 Jupiter Notebook 来探索每一部分功能的实现还是很有用的，因为随时可视化你的想法。本项目中分别就分类和检测两部分建立了两个 Notebook，就 图片裁切和结果 image 重绘也建了个 Notebook，每个部分分别实现成功后，进行融合即得到项目主要代码。
- Finetune 训练要时刻关注训练集上 loss 变化及目标准确率的增长，在 loss 升高或波动很大等情况下及时调整学习率或者终止训练。
- 使用模型的时候先要搞清楚输入输出各个 tensor 的 shape，好进行之后的操作。


### 项目不足与改进设想

- 项目暂时只识别图片中最明显的一辆车，没有针对有多辆车都比较清晰明显的情况做识别。如果针对停车场那种场景，还是可以接受的。考虑针对检测部分产生的所有分类为 car 的 bounding box，都在原图上进行裁切，然后所有裁切后的部分经过分类模型的 inference 产生多辆车的识别结果。
- 每次上传图片做 inference 时都要重新加载一遍模型，耗时较长。将初始化模型部分独立出来，在 post 之前加载并常驻内存。
- 项目选择 bounding box 时，观察分类为 car 的 b-box 是按置信度降序排列的，因而选择了其中的第一个。然而实际应用时会发现，第一个 b-box 可能并不是图上最明显的那辆车，甚至可能只是一辆车的部分。因此，还是针对多辆车检测进行修改才能得到比较好的效果。
- 分类模型在校验集上准确率为 83%，并不是特别好，而且训练到后面准确率基本没什么提升空间了。还是继续尝试一些更好的模型及优化求解器等等。
- 项目安装还是有点繁琐，感觉最好能精简一下，或者傻瓜式安装最好。项目发布形式还是有点简单。

